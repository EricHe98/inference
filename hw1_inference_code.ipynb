{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference HW1 - Problem 4\n",
    "\n",
    "## Eric He / eh1885 / N16436011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be storing the data as a list of dicts.\n",
    "Each dict corresponds to an email. The dict has three keys.\n",
    "\n",
    "1. The `id` key represents the ID of the email.\n",
    "2. The `label` key represents whether the email is ham or spam.\n",
    "3. The `words` key links to a nested dict, where each key corresponds to a word in the email and the value the corresponding frequency of that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train', 'r') as handle:\n",
    "    raw_train = handle.readlines()\n",
    "with open('data/test', 'r') as handle:\n",
    "    raw_test = handle.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse one email\n",
    "def read_row(l):\n",
    "    i = 2\n",
    "    l = l.split(' ')\n",
    "    a = dict()\n",
    "    a['id'] = l[0]\n",
    "    a['label'] = l[1]\n",
    "    a['words'] = dict()\n",
    "    # fill up words dictionary\n",
    "    while i < len(l):\n",
    "        a['words'][l[i]] = l[i + 1]\n",
    "        i = i+2\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list()\n",
    "for l in raw_train:\n",
    "    train.append(read_row(l))\n",
    "test = list()\n",
    "for l in raw_test:\n",
    "    test.append(read_row(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) What is $p(\\text{Spam})$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    0.573667\n",
       "ham     0.426333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = [l['label'] for l in train]\n",
    "spam_rates = pd.Series(train_labels).value_counts() / pd.Series(train_labels).value_counts().sum()\n",
    "spam_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Compute a smoothed $P(w_i | \\text{Spam})$ and $P(w_i | \\text{Ham})$\n",
    "\n",
    "where the smoothing corresponds to $\\dfrac{n_c + mp}{n + m} = \\dfrac{n_c + 1}{n + m}$, with $n$ being number of spam (ham) words, $n_c$ being the number of spam (ham) instances of that word, and $m$ is the number of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_bank = set([w for l in train for w in l['words']])\n",
    "word_dict_spam = {}\n",
    "word_dict_ham = {}\n",
    "\n",
    "spam_count = np.sum([int(l['words'].get(w)) for l in train if l['label'] == 'spam' for w in l['words']])\n",
    "ham_count = np.sum([int(l['words'].get(w)) for l in train if l['label'] != 'spam' for w in l['words']])\n",
    "vocabulary_count = np.sum([int(l['words'].get(w)) for l in train for w in l['words']])\n",
    "\n",
    "for w in word_bank:\n",
    "    word_dict_spam[w] = (np.sum([int(l['words'].get(w)) \\\n",
    "                                 for l in train if l['words'].get(w) and l['label'] == 'spam']) + 1.0)\\\n",
    "        / (spam_count + vocabulary_count)\n",
    "    word_dict_ham[w] = (np.sum([int(l['words'].get(w)) \\\n",
    "                                for l in train if l['words'].get(w) and l['label'] != 'spam']) + 1.0) \\\n",
    "        / (ham_count + vocabulary_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 spam words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enron    0.012941\n",
       "a        0.008003\n",
       "corp     0.007365\n",
       "the      0.007259\n",
       "to       0.006670\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_probabilities = pd.Series(word_dict_spam)\n",
    "spam_probabilities.sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 ham words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa    0.014545\n",
       "enron                                                                           0.013929\n",
       "the                                                                             0.010885\n",
       "to                                                                              0.008312\n",
       "a                                                                               0.005821\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_probabilities = pd.Series(word_dict_ham)\n",
    "ham_probabilities.sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Build a Naive Bayes model and predict on the test set\n",
    "\n",
    "We use a Naive Bayes model of completely binary features where we merely look at the presence of each distinct word in the email and ignore its frequency.\n",
    "\n",
    "For each email, this model will look at each **distinct** word, and add that word's log-probability of being spam to the spam score, and its log-probability of being ham to the ham score. Then, the model compares the spam score to the ham score; if the spam score is equal or higher, then the email is spam; otherwise, the email is ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.921"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_lp = np.log(ham_probabilities)\n",
    "spam_lp = np.log(spam_probabilities)\n",
    "def NaiveBayes(l, ham_lp, spam_lp):\n",
    "    ham_score = ham_lp[l['words'].keys()].sum() + np.log(spam_rates[1])\n",
    "    spam_score = spam_lp[l['words'].keys()].sum() + np.log(spam_rates[0])\n",
    "    if spam_score >= ham_score:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'\n",
    "pred = [NaiveBayes(l, ham_lp, spam_lp) for l in test]\n",
    "truth = [l['label'] for l in test]\n",
    "accuracy = np.sum([1 for i in range(len(pred)) if pred[i] == truth[i]]) / len(pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Vary the prior\n",
    "The accuracy starts dropping for higher values of $m$. This is because when we have a large $m$, our probabilities of a word corresponding to fraud or not fraud converge to the uniform distribution, meaning that we are less certain of whether or not the word corresponds to a fraudulent email. Since our initial model was good and not overfitting, this smoothing prior served to over-regularize our model and reduce the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = 10.0**np.array(range(5))\n",
    "\n",
    "raw_occurrences_spam = {}\n",
    "raw_occurrences_ham = {}\n",
    "for w in word_bank:\n",
    "    raw_occurrences_spam[w] = np.sum([int(l['words'].get(w)) \\\n",
    "                                      for l in train if l['words'].get(w) and l['label'] == 'spam'])\n",
    "    raw_occurrences_ham[w] = np.sum([int(l['words'].get(w)) \\\n",
    "                                     for l in train if l['words'].get(w) and l['label'] != 'spam'])\n",
    "\n",
    "accuracies = []\n",
    "for m in ms:\n",
    "    spam_lp = np.log(pd.Series(raw_occurrences_spam) + float(m)) \\\n",
    "        - np.log(spam_count + m * float(vocabulary_count))\n",
    "    ham_lp = np.log(pd.Series(raw_occurrences_ham) + float(m)) \\\n",
    "        - np.log(ham_count + m * float(vocabulary_count))\n",
    "    pred = [NaiveBayes(l, ham_lp, spam_lp) for l in test]\n",
    "    accuracy = np.sum([1 for i in range(len(pred)) if pred[i] == truth[i]]) / len(pred)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.plot(ms, accuracies, '.')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) How would you game this model?\n",
    "I would find every single word with a higher ham log-probability than spam log-probability and have a large number of them pasted into each of my spam emails in white text to ensure extremely low predicted probability of spam."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
